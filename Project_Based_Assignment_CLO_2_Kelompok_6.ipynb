{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R-Kani/R-Kani/blob/main/Project_Based_Assignment_CLO_2_Kelompok_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0998ab93"
      },
      "source": [
        "# <center>Project-Based Assignment CLO-2</center>"
      ],
      "id": "0998ab93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9dd2c3d"
      },
      "source": [
        "<b>Topik : </b>\n",
        "Implementation of Supervised Learning on Regression Task\n",
        "\n",
        "<b>Anggota Kelompok</b>\n",
        "1. I Made Denis Maharditha - 1301210537\n",
        "2. Putri Maharani - 1301213093\n",
        "3. Ratin Kani - 1301213269"
      ],
      "id": "b9dd2c3d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f67c8e8d"
      },
      "source": [
        "### Latar Belakang\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Latar belakang proyek ini adalah upaya untuk memenuhi persyaratan Tugas Project-Based Assignment CLO-2 dalam mata kuliah Machine Learning. Proyek ini mendorong penerapan konsep pembelajaran mesin dalam pemecahan masalah dunia nyata dengan fokus pada metode Support Vector Machine (SVM) untuk tugas regresi. Regresi adalah konsep fundamental dalam machine learning yang memungkinkan untuk memprediksi hasil berdasarkan variabel input. Dalam proyek ini dataset yang diekplorasi adalah  \"Seoul Bike Sharing Demand‚Äù yang dapat diakses melalui https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand. Proyek ini bertujuan untuk memanfaatkan teknologi machine learning guna memahami dan meramalkan permintaan sepeda berdasarkan faktor-faktor seperti kondisi cuaca meliputi musim, suhu, kelembapan, kecepatan angin, jarak pandang, suhu titik embun, radiasi matahari, curah hujan, dan salju. Serta faktor waktu yang meliputi jam, hari libur, dan hari kerja.  Dengan tujuan ini, diharapkan akan memperdalam pemahaman tentang machine learning, menerapkan teknik regresi melalui SVM, melakukan pra-pemrosesan data untuk mengoptimalkan kualitas dataset, serta melakukan eksplorasi untuk memahami pola-pola dalam data dengan menciptakan beberapa model dengan variasi parameter guna menentukan model terbaik yang dapat mengatasi tugas regresi ini secara efisien. Dengan demikian, tugas ini tidak hanya memenuhi persyaratan mata kuliah Machine Learning tetapi juga memberikan kesempatan berharga untuk menguasai penggunaan metode SVM dalam konteks pemodelan regresi untuk aplikasi dunia nyata, seperti pengelolaan penyewaan sepeda di kota Seoul."
      ],
      "id": "f67c8e8d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jLkMvk8Xz7v"
      },
      "source": [
        "### Data Preprocessing dan Eksplorasi Data\n",
        " Proses membersihkan, merapikan, dan mempersiapkan data mentah untuk analisis, serta tahap awal untuk memahami dan identifikasi pola data"
      ],
      "id": "6jLkMvk8Xz7v"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg0ptqFzWuvO"
      },
      "source": [
        "#### Import Library\n"
      ],
      "id": "qg0ptqFzWuvO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd1c9727"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "id": "bd1c9727"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeYJlB-hXHjy"
      },
      "source": [
        "#### Import Dataset"
      ],
      "id": "NeYJlB-hXHjy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7769541"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('SeoulBikeData.csv', encoding='latin1')\n",
        "X = dataset.iloc[:, 2:].values\n",
        "Y = dataset.iloc[:, 1].values"
      ],
      "id": "f7769541"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhq1drO_y9xm"
      },
      "source": [
        "Menampilkan beberapa baris pertama dari X"
      ],
      "id": "Fhq1drO_y9xm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trlJ2Tm_qGPW",
        "outputId": "f60c2d44-2429-4639-8f31-273033b7b03c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Head of X:\n",
            "[[0 -5.2 37 2.2 2000 -17.6 0.0 0.0 0.0 'Winter' 'No Holiday' 'Yes']\n",
            " [1 -5.5 38 0.8 2000 -17.6 0.0 0.0 0.0 'Winter' 'No Holiday' 'Yes']\n",
            " [2 -6.0 39 1.0 2000 -17.7 0.0 0.0 0.0 'Winter' 'No Holiday' 'Yes']\n",
            " [3 -6.2 40 0.9 2000 -17.6 0.0 0.0 0.0 'Winter' 'No Holiday' 'Yes']\n",
            " [4 -6.0 36 2.3 2000 -18.6 0.0 0.0 0.0 'Winter' 'No Holiday' 'Yes']]\n"
          ]
        }
      ],
      "source": [
        "print(\"Head of X:\")\n",
        "print(X[:5, :])"
      ],
      "id": "trlJ2Tm_qGPW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ueiUqmKzBGG"
      },
      "source": [
        "Menampilkan beberapa baris pertama dari Y"
      ],
      "id": "2ueiUqmKzBGG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0egPwiqBqFSN",
        "outputId": "6ec9df3d-b2ea-4bf4-f39e-57ea6de5379c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Head of Y:\n",
            "[254 204 173 107  78]\n"
          ]
        }
      ],
      "source": [
        "print(\"Head of Y:\")\n",
        "print(Y[:5])"
      ],
      "id": "0egPwiqBqFSN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPXvFPOoXfJK"
      },
      "source": [
        "#### Pengkodean Variabel Independen"
      ],
      "id": "fPXvFPOoXfJK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpOgiP3dxcO-"
      },
      "source": [
        "##### Mengubah variabel kategorikal atau label menjadi bilangan bulat\n",
        "Untuk Kolom Ke-10, Keterangan \"No Holiday\" menjadi 0, dan \"Holiday\" menjadi 1\n",
        "\n",
        "Untuk Kolom Ke-11, Keterangan \"No\" menjadi 0, dan \"Yes\" menjadi 1\n"
      ],
      "id": "vpOgiP3dxcO-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUKzWWniXktl"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "X[:, 10] = 1-le.fit_transform(X[:, 10])\n",
        "X[:, 11] = le.fit_transform(X[:, 11])"
      ],
      "id": "sUKzWWniXktl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8seTiyXfyqYe"
      },
      "source": [
        "Menampilkan beberapa baris pertama dari X Setelah dilakukan LabelEncoder"
      ],
      "id": "8seTiyXfyqYe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1IygEBfqrAl",
        "outputId": "6cfd505a-5e11-45f2-f8db-f228abd089f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Head of X:\n",
            "[[0 -5.2 37 2.2 2000 -17.6 0.0 0.0 0.0 'Winter' 0 1]\n",
            " [1 -5.5 38 0.8 2000 -17.6 0.0 0.0 0.0 'Winter' 0 1]\n",
            " [2 -6.0 39 1.0 2000 -17.7 0.0 0.0 0.0 'Winter' 0 1]\n",
            " [3 -6.2 40 0.9 2000 -17.6 0.0 0.0 0.0 'Winter' 0 1]\n",
            " [4 -6.0 36 2.3 2000 -18.6 0.0 0.0 0.0 'Winter' 0 1]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Head of X:\")\n",
        "print(X[:5, :])"
      ],
      "id": "a1IygEBfqrAl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGJi1Cle1mUF"
      },
      "source": [
        "Mengubah variabel kategorikal menjadi representasi one-hot encoding, dimana setiap kategori diubah menjadi kolom terpisah dengan nilai 1 menunjukkan kehadiran kategori tersebut dan nilai 0 menunjukkan ketidakhadiran kategori tersebut"
      ],
      "id": "IGJi1Cle1mUF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEtCSuCwXqU3"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [9])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "id": "LEtCSuCwXqU3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIb1_2cD2Ov0"
      },
      "source": [
        "Menampilkan beberapa baris pertama dari X Setelah dilakukan OneHotlEncoder"
      ],
      "id": "aIb1_2cD2Ov0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXPPClHc2UUR",
        "outputId": "0f7a80e2-3a46-444e-e117-365108346a6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Head of X:\n",
            "[[0.0 0.0 0.0 1.0 0 -5.2 37 2.2 2000 -17.6 0.0 0.0 0.0 0 1]\n",
            " [0.0 0.0 0.0 1.0 1 -5.5 38 0.8 2000 -17.6 0.0 0.0 0.0 0 1]\n",
            " [0.0 0.0 0.0 1.0 2 -6.0 39 1.0 2000 -17.7 0.0 0.0 0.0 0 1]\n",
            " [0.0 0.0 0.0 1.0 3 -6.2 40 0.9 2000 -17.6 0.0 0.0 0.0 0 1]\n",
            " [0.0 0.0 0.0 1.0 4 -6.0 36 2.3 2000 -18.6 0.0 0.0 0.0 0 1]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Head of X:\")\n",
        "print(X[:5, :])"
      ],
      "id": "GXPPClHc2UUR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g62QLlR3YFoh"
      },
      "source": [
        "#### Memisahkan Dataset Menjadi Data Latih (Training Set) dan Data Uji (Test Set)"
      ],
      "id": "g62QLlR3YFoh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EagrKchC2zsW"
      },
      "source": [
        "Membagi dataset menjadi dua bagian, yaitu data pelatihan (X_train dan Y_train) dan data pengujian (X_test dan Y_test) , yang dalam kasus ini, dataset akan dibagi menjadi data pelatihan (75%) dan data pengujian (25%)."
      ],
      "id": "EagrKchC2zsW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTvHvTgYYWbr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
      ],
      "id": "HTvHvTgYYWbr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKw0V08OYY8n"
      },
      "source": [
        "#### Penskalaan Fitur (Feature Scaling)"
      ],
      "id": "mKw0V08OYY8n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oCRx9gc3Poa"
      },
      "source": [
        "Melakukan penskalaan fitur sehingga rerata (mean) sekitar 0 dan simpangan baku (standard deviation) sekitar 1"
      ],
      "id": "6oCRx9gc3Poa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgfWIGJ7YhTf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "id": "RgfWIGJ7YhTf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbk5SDx13Yeq"
      },
      "source": [
        "Menampilkan beberapa baris pertama dari X_train dan X_test Setelah dilakukan Feature Scaling"
      ],
      "id": "fbk5SDx13Yeq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tAc_Vf_3ets",
        "outputId": "9debed2a-845e-4a19-d423-3a7fce778f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Head of X_train:\n",
            "[[ 1.72819284 -0.5807482  -0.57582707 -0.57418668  1.66765533 -0.74954694\n",
            "   1.22697808 -0.60031734 -1.72479535 -0.21606478 -0.65549033 -0.12622668\n",
            "   0.75014943 -0.23069934  0.17946416]\n",
            " [-0.57863913  1.72191666 -0.57582707 -0.57418668  0.36544652  0.93615918\n",
            "  -0.54181953  0.55489426 -1.51110252  0.60963914  2.63117329 -0.12622668\n",
            "  -0.17270082 -0.23069934  0.17946416]\n",
            " [-0.57863913 -0.5807482  -0.57582707  1.74159386  1.08889586 -1.65916064\n",
            "  -1.22968527  0.26609136  0.73595975 -1.87511801 -0.65549033 -0.12622668\n",
            "  -0.17270082 -0.23069934  0.17946416]\n",
            " [-0.57863913  1.72191666 -0.57582707 -0.57418668  0.07606679 -0.04021516\n",
            "   1.91484382 -0.88912024 -1.97465158  0.60199373 -0.49516527  1.59826753\n",
            "  -0.17270082 -0.23069934  0.17946416]\n",
            " [ 1.72819284 -0.5807482  -0.57582707 -0.57418668 -1.08145215 -0.7662371\n",
            "   0.58824561 -0.88912024  0.81321793 -0.39955453 -0.65549033 -0.12622668\n",
            "  -0.17270082 -0.23069934  0.17946416]]\n",
            "\n",
            "Head of X_test:\n",
            "[[-5.78639130e-01  1.72191666e+00 -5.75827069e-01 -5.74186682e-01\n",
            "  -1.22614202e+00 -1.73736433e-01  7.35645409e-01 -4.07782076e-01\n",
            "   9.21708131e-01  1.58560147e-01 -6.55490327e-01 -1.26226676e-01\n",
            "  -1.72700820e-01 -2.30699342e-01  1.79464158e-01]\n",
            " [ 1.72819284e+00 -5.80748200e-01 -5.75827069e-01 -5.74186682e-01\n",
            "  -1.37083188e+00  7.44222349e-01  9.81311744e-01 -6.96584977e-01\n",
            "   9.21708131e-01  1.04542731e+00 -6.55490327e-01 -1.26226676e-01\n",
            "  -1.72700820e-01 -2.30699342e-01  1.79464158e-01]\n",
            " [-5.78639130e-01 -5.80748200e-01 -5.75827069e-01  1.74159386e+00\n",
            "   7.99516125e-01 -7.66237101e-01  3.42579273e-01  2.48024693e+00\n",
            "  -6.21811602e-01 -4.76008601e-01 -6.21134958e-01 -1.26226676e-01\n",
            "   7.50149434e-01 -2.30699342e-01  1.79464158e-01]\n",
            " [-5.78639130e-01 -5.80748200e-01 -5.75827069e-01  1.74159386e+00\n",
            "   1.52296546e+00 -1.87613272e+00 -3.45286464e-01  1.03623243e+00\n",
            "   9.21708131e-01 -1.66869203e+00 -6.55490327e-01 -1.26226676e-01\n",
            "  -1.72700820e-01 -2.30699342e-01  1.79464158e-01]\n",
            " [-5.78639130e-01 -5.80748200e-01  1.73663249e+00 -5.74186682e-01\n",
            "   5.10136391e-01  1.73728685e+00 -1.35359533e-03  1.80637349e+00\n",
            "   1.43355087e-02  1.54237874e+00  1.61196401e+00 -1.26226676e-01\n",
            "  -1.72700820e-01 -2.30699342e-01  1.79464158e-01]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Head of X_train:\")\n",
        "print(X_train[:5, :])\n",
        "\n",
        "print(\"\\nHead of X_test:\")\n",
        "print(X_test[:5, :])"
      ],
      "id": "9tAc_Vf_3ets"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "691b437e"
      },
      "source": [
        "### Ringkasan Metode\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Metode yang digunakan dalam tugas ini adalah Support Vector Machine for Regression (SVR), sebuah pendekatan yang sangat efektif untuk tugas regresi. SVR berfokus pada pencarian garis regresi yang optimal dengan tujuan meminimalkan deviasi antara titik data sebanyak mungkin, sambil mempertimbangkan toleransi kesalahan yang dapat diterima. Tahapan implementasi SVR mencakup pra-pemrosesan, eksplorasi data, pembangunan model baseline dimana merupakan sebuah model pelatihan sederhana dengan parameter-parameter default, dan tidak melibatkan tuning atau kompleksitas tambahan. Dilanjutkan dengan eksplorasi Model dengan membangun beberapa skema model melalui proses hyperparameter tuning atau pemilihan kombinasi parameter yang bervariasi melalui validasi silang (cross-validation) untuk mengidentifikasi kernel dan nilai parameter C yang menghasilkan model SVR dengan kinerja terbaik dalam memprediksi nilai target. Evaluasi model dilakukan dengan metrik seperti Mean Absolute Error (MAE) dan R-Square (R¬≤), yang memberikan pandangan tentang seberapa baik model ini memodelkan hubungan antara variabel input, seperti cuaca dan waktu, dengan permintaan sepeda dalam dataset Seoul Bike Sharing Demand.\n",
        "\n"
      ],
      "id": "691b437e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIVLWa9NY4_W"
      },
      "source": [
        "### Pembangunan Model Baseline\n",
        "Pembuatan model yang sederhana dengan parameter-parameter default, dan tidak melibatkan tuning atau kompleksitas tambahan."
      ],
      "id": "JIVLWa9NY4_W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfUsmwVjJp17"
      },
      "outputs": [],
      "source": [
        "class linearKernel:\n",
        "    # Konstruktor inisialisasi parameter-model dan atribut\n",
        "    def __init__(self, C=1.0, epsilon=0.1, max_iterations=1000, learning_rate=0.01):\n",
        "        self.C = C  # Parameter regulasi SVR\n",
        "        self.epsilon = epsilon  # Toleransi kesalahan\n",
        "        self.max_iterations = max_iterations  # Jumlah iterasi maksimum\n",
        "        self.learning_rate = learning_rate  # Laju pembelajaran\n",
        "        self.alpha = None  # Bobot alpha dari model\n",
        "        self.X_train = None  # Data pelatihan\n",
        "        self.weights = None  # Bobot yang akan dihitung selama pelatihan\n",
        "        self.bias = None  # Bias yang akan dihitung selama pelatihan\n",
        "\n",
        "    # Fungsi kernel linear untuk menghitung kesamaan antara dua vektor\n",
        "    def linear_kernel(self, xi, xj):\n",
        "        return np.dot(self.weights, xi) * np.dot(self.weights, xj)\n",
        "\n",
        "    # Melatih model SVR dengan kernel linear\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        n_samples, n_features = X.shape\n",
        "        self.alpha = np.zeros(n_samples)\n",
        "        self.weights = np.ones(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Inisialisasi matriks kernel K\n",
        "        K = np.zeros((n_samples, n_samples))\n",
        "\n",
        "        # Mengisi matriks kernel K dengan nilai-nilai kernel linear antara pasangan data pelatihan\n",
        "        for i in range(n_samples):\n",
        "            for j in range(n_samples):\n",
        "                K[i, j] = self.linear_kernel(X[i], X[j])\n",
        "\n",
        "        # Iterasi pelatihan model SVR dengan kernel linear\n",
        "        for _ in range(self.max_iterations):\n",
        "            for i in range(n_samples):\n",
        "                error = y[i] - (np.dot(self.alpha, K[i]) + self.bias)\n",
        "\n",
        "                # Update bobot (weights) dan bias berdasarkan error\n",
        "                if error < -self.epsilon: # Kodisi jika error di bawah -epsilon\n",
        "                    self.weights += self.learning_rate * (2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias) * X[i] - self.weights)\n",
        "                    self.bias += self.learning_rate * 2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias)\n",
        "                elif error > self.epsilon: # Kodisi jika error di atas epsilon\n",
        "                    self.weights += self.learning_rate * (2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias) * X[i] - self.weights)\n",
        "                    self.bias += self.learning_rate * 2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias)\n",
        "\n",
        "        return self\n",
        "\n",
        "    # Membuat prediksi menggunakan model SVR yang sudah dilatih\n",
        "    def predict(self, X_test):\n",
        "      n_samples, _ = X_test.shape\n",
        "      y_pred = np.zeros(n_samples)\n",
        "\n",
        "      # Iterasi untuk menghitung prediksi untuk setiap sampel\n",
        "      for i in range(n_samples):\n",
        "        y_pred[i] = np.dot(X_test[i], self.weights) + self.bias\n",
        "      return y_pred"
      ],
      "id": "XfUsmwVjJp17"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2T2laZ03nRu"
      },
      "source": [
        "Pelatihan model SVR dengan kernel linear yang telah implementasikan sebelumnya"
      ],
      "id": "Y2T2laZ03nRu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID8NebLgPLAS",
        "outputId": "6b521fee-0eca-4f92-b195-dc9e5c22389d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.linearKernel at 0x7a6eb17902e0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svr = linearKernel(C=0.1, epsilon=0.2, max_iterations=10, learning_rate=0.01)\n",
        "svr.fit(X_train, Y_train)"
      ],
      "id": "ID8NebLgPLAS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR7gth2f55JD"
      },
      "source": [
        "Membuat prediksi pada data pengujian."
      ],
      "id": "IR7gth2f55JD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0nwArF8KQWo"
      },
      "outputs": [],
      "source": [
        "Y_pred = svr.predict(X_test)"
      ],
      "id": "O0nwArF8KQWo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCaHCWq76CR2"
      },
      "source": [
        "Mendefinisikan fungsi yang digunakan untuk menghitung metrik evaluasi kinerja model regresi, yaitu Mean Squared Error (MSE) dan R-squared (R¬≤)."
      ],
      "id": "nCaHCWq76CR2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axv4mIeycuXY"
      },
      "outputs": [],
      "source": [
        "# Hitung Mean Squared Error (MSE)\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mse = sum((y_true[i] - y_pred[i]) ** 2 for i in range(n)) / n\n",
        "    return mse\n",
        "\n",
        "# Hitung R-squared (R¬≤)\n",
        "def r_squared(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mean_y = sum(y_true) / n\n",
        "    ssr = sum((y_true[i] - y_pred[i]) ** 2 for i in range(n))\n",
        "    sst = sum((y_true[i] - mean_y) ** 2 for i in range(n))\n",
        "    r2 = 1 - (ssr / sst)\n",
        "    return r2"
      ],
      "id": "Axv4mIeycuXY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O_FD8kN6GlT"
      },
      "source": [
        "Menampilkan hasil perhitungan MSE dan R¬≤ untuk Baseline Model\n",
        "\n",
        "\n"
      ],
      "id": "3O_FD8kN6GlT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYjNBrxQRCKI",
        "outputId": "0cc824ce-8699-4f4d-cc85-f0e3f2b42859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE) Untuk Baseline Model : 313096.9025837174\n",
            "R-squared (R¬≤) Untuk Baseline Model : 0.24936565008280565\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "print(\"Mean Squared Error (MSE) Untuk Baseline Model :\", mse)\n",
        "\n",
        "r2 = r_squared(Y_test, Y_pred)\n",
        "print(\"R-squared (R¬≤) Untuk Baseline Model :\", r2)"
      ],
      "id": "CYjNBrxQRCKI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErNoFgoBQtWQ"
      },
      "source": [
        "### Eksplorasi Model\n",
        "\n",
        "\n"
      ],
      "id": "ErNoFgoBQtWQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlNasMnteb6Y"
      },
      "source": [
        "####  Implementasi Kelas SVR Dengan Kernel RBF"
      ],
      "id": "QlNasMnteb6Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wByXGlUeecxJ"
      },
      "outputs": [],
      "source": [
        "class rbfKernel:\n",
        "    # Konstruktor inisialisasi parameter-model dan atribut\n",
        "    def __init__(self, C=1.0, epsilon=0.1, max_iterations=1000, learning_rate=0.01, gamma=1.0):\n",
        "        self.C = C  # Parameter regulasi SVR\n",
        "        self.epsilon = epsilon  # Toleransi kesalahan\n",
        "        self.max_iterations = max_iterations  # Jumlah iterasi maksimum\n",
        "        self.learning_rate = learning_rate  # Laju pembelajaran\n",
        "        self.gamma = gamma  # Parameter gamma untuk kernel RBF\n",
        "        self.alpha = None  # Bobot alpha dari model\n",
        "        self.X_train = None  # Data pelatihan\n",
        "        self.weights = None  # Bobot yang akan dihitung selama pelatihan\n",
        "        self.bias = None  # Bias yang akan dihitung selama pelatihan\n",
        "\n",
        "    # Fungsi kernel RBF untuk menghitung kesamaan antara dua vektor\n",
        "    def rbf_kernel(self, xi, xj):\n",
        "        return np.exp(-self.gamma * np.linalg.norm(xi - xj) ** 2)\n",
        "\n",
        "    # Melatih model SVR dengan kernel RBF\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        n_samples, n_features = X.shape\n",
        "        self.alpha = np.zeros(n_samples)\n",
        "        self.weights = np.ones(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Inisialisasi matriks kernel K\n",
        "        K = np.zeros((n_samples, n_samples))\n",
        "\n",
        "        # Mengisi matriks kernel K dengan nilai-nilai kernel RBF antara pasangan data pelatihan\n",
        "        for i in range(n_samples):\n",
        "            for j in range(n_samples):\n",
        "                K[i, j] = self.rbf_kernel(X[i], X[j])\n",
        "\n",
        "        # Iterasi pelatihan model SVR dengan kernel RBF\n",
        "        for _ in range(self.max_iterations):\n",
        "            for i in range(n_samples):\n",
        "                error = y[i] - (np.dot(self.alpha, K[i]) + self.bias)\n",
        "\n",
        "                # Update bobot (weights) dan bias berdasarkan error\n",
        "                if error < -self.epsilon: # Kodisi jika error di bawah -epsilon\n",
        "                    self.weights += self.learning_rate * (self.alpha[i] * y[i] * self.rbf_kernel(X[i], X[i]) - self.alpha @ K[i])\n",
        "                    self.bias += self.learning_rate * 2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias)\n",
        "                elif error > self.epsilon: # Kodisi jika error di atas epsilon\n",
        "                    self.weights += self.learning_rate * (self.alpha[i] * y[i] * self.rbf_kernel(X[i], X[i]) - self.alpha @ K[i])\n",
        "                    self.bias += self.learning_rate * 2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias)\n",
        "\n",
        "        return self\n",
        "\n",
        "    # Membuat prediksi menggunakan model SVR yang sudah dilatih\n",
        "    def predict(self, X_test):\n",
        "        n_samples, _ = X_test.shape\n",
        "        y_pred = np.zeros(n_samples)\n",
        "\n",
        "        # Iterasi untuk menghitung prediksi untuk setiap sampel\n",
        "        for i in range(n_samples):\n",
        "            y_pred[i] = np.dot(X_test[i], self.weights) + self.bias\n",
        "        return y_pred"
      ],
      "id": "wByXGlUeecxJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioWJjQrefJJI"
      },
      "source": [
        "####  Implementasi Kelas SVR Dengan Kernel Polynomial"
      ],
      "id": "ioWJjQrefJJI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad0BKJyGfIAM"
      },
      "outputs": [],
      "source": [
        "class polyKernel:\n",
        "    # Konstruktor inisialisasi parameter-model dan atribut\n",
        "    def __init__(self, C=1.0, epsilon=0.1, max_iterations=1000, learning_rate=0.01, degree=2):\n",
        "        self.C = C  # Parameter regulasi SVR\n",
        "        self.epsilon = epsilon  # Toleransi kesalahan\n",
        "        self.max_iterations = max_iterations  # Jumlah iterasi maksimum\n",
        "        self.learning_rate = learning_rate  # Laju pembelajaran\n",
        "        self.degree = degree  # Derajat polinomial untuk kernel\n",
        "        self.alpha = None  # Bobot alpha dari model\n",
        "        self.X_train = None  # Data pelatihan\n",
        "        self.weights = None  # Bobot yang akan dihitung selama pelatihan\n",
        "        self.bias = None  # Bias yang akan dihitung selama pelatihan\n",
        "\n",
        "    # Fungsi kernel polinomial untuk menghitung kesamaan antara dua vektor\n",
        "    def poly_kernel(self, xi, xj):\n",
        "        return (np.dot(xi, xj) + 1) ** self.degree\n",
        "\n",
        "    # Melatih model SVR dengan kernel polinomial\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        n_samples, n_features = X.shape\n",
        "        self.alpha = np.zeros(n_samples)\n",
        "        self.weights = np.ones(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Inisialisasi matriks kernel K\n",
        "        K = np.zeros((n_samples, n_samples))\n",
        "\n",
        "        # Mengisi matriks kernel K dengan nilai-nilai kernel polinomial antara pasangan data pelatihan\n",
        "        for i in range(n_samples):\n",
        "            for j in range(n_samples):\n",
        "                K[i, j] = self.poly_kernel(X[i], X[j])\n",
        "\n",
        "        # Iterasi pelatihan model SVR dengan kernel polinomial\n",
        "        for _ in range(self.max_iterations):\n",
        "            for i in range(n_samples):\n",
        "                error = y[i] - (np.dot(self.alpha, K[i]) + self.bias)\n",
        "\n",
        "                # Update bobot (weights) dan bias berdasarkan error\n",
        "                if error < -self.epsilon: # Kodisi jika error di bawah -epsilon\n",
        "                    self.weights += self.learning_rate * (2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias) * X[i] - self.weights)\n",
        "                    self.bias += self.learning_rate * 2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias)\n",
        "                elif error > self.epsilon: # Kodisi jika error di atas epsilon\n",
        "                    self.weights += self.learning_rate * (2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias) * X[i] - self.weights)\n",
        "                    self.bias += self.learning_rate * 2 * self.C * (y[i] - np.dot(X[i], self.weights) - self.bias)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        n_samples, _ = X_test.shape\n",
        "        y_pred = np.zeros(n_samples)\n",
        "\n",
        "        # Iterasi untuk menghitung prediksi untuk setiap sampel\n",
        "        for i in range(n_samples):\n",
        "            y_pred[i] = np.dot(X_test[i], self.weights) + self.bias\n",
        "        return y_pred"
      ],
      "id": "Ad0BKJyGfIAM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCbJzpm6XWJq"
      },
      "source": [
        "#### Hyperparameter tuning dengan metode grid search\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "id": "TCbJzpm6XWJq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UZaMwPJq5I8"
      },
      "source": [
        "Eksplorasi kombinasi hyperparameter untuk model Support Vector Regression (SVR) dengan berbagai jenis kernel, yaitu linear, rbf, dan polynomial dan nilai parameter C yaitu 0.1, 1.0, dan 3.0, dengan setiap kombinasi model SVR dilatih dan dievaluasi menggunakan teknik cross-validation atau dalam kasus ini, menggunakan 3-fold cross-validation"
      ],
      "id": "-UZaMwPJq5I8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV2TThf1BVtR",
        "outputId": "83cb4f92-dc1b-4f34-9872-9f2714baea86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel: linear, C: 0.1, Fold: 1, MSE: 304863.89245975233\n",
            "Kernel: linear, C: 0.1, Fold: 2, MSE: 305519.1595831723\n",
            "Kernel: linear, C: 0.1, Fold: 3, MSE: 307857.76819647825\n",
            "Rata - rata score: 306080.2734131343\n",
            "Kernel: linear, C: 1.0, Fold: 1, MSE: 212543.77460390184\n",
            "Kernel: linear, C: 1.0, Fold: 2, MSE: 210423.30640325756\n",
            "Kernel: linear, C: 1.0, Fold: 3, MSE: 244347.68593778423\n",
            "Rata - rata score: 222438.25564831457\n",
            "Kernel: linear, C: 3.0, Fold: 1, MSE: 321697.3212948815\n",
            "Kernel: linear, C: 3.0, Fold: 2, MSE: 310314.0689813253\n",
            "Kernel: linear, C: 3.0, Fold: 3, MSE: 423485332.97341436\n",
            "Rata - rata score: 141372448.12123019\n",
            "Kernel: rbf, C: 0.1, Fold: 1, MSE: 411423.5104657404\n",
            "Kernel: rbf, C: 0.1, Fold: 2, MSE: 413639.61254340014\n",
            "Kernel: rbf, C: 0.1, Fold: 3, MSE: 416457.35565282474\n",
            "Rata - rata score: 413840.15955398843\n",
            "Kernel: rbf, C: 1.0, Fold: 1, MSE: 412288.20457607775\n",
            "Kernel: rbf, C: 1.0, Fold: 2, MSE: 414599.3430737152\n",
            "Kernel: rbf, C: 1.0, Fold: 3, MSE: 418724.30799537577\n",
            "Rata - rata score: 415203.95188172295\n",
            "Kernel: rbf, C: 3.0, Fold: 1, MSE: 419344.24139571993\n",
            "Kernel: rbf, C: 3.0, Fold: 2, MSE: 422015.2143450735\n",
            "Kernel: rbf, C: 3.0, Fold: 3, MSE: 434143.6078323963\n",
            "Rata - rata score: 425167.68785772985\n",
            "Kernel: poly, C: 0.1, Fold: 1, MSE: 304863.89245975233\n",
            "Kernel: poly, C: 0.1, Fold: 2, MSE: 305519.1595831723\n",
            "Kernel: poly, C: 0.1, Fold: 3, MSE: 307857.76819647825\n",
            "Rata - rata score: 306080.2734131343\n",
            "Kernel: poly, C: 1.0, Fold: 1, MSE: 212543.77460390184\n",
            "Kernel: poly, C: 1.0, Fold: 2, MSE: 210423.30640325756\n",
            "Kernel: poly, C: 1.0, Fold: 3, MSE: 244347.68593778423\n",
            "Rata - rata score: 222438.25564831457\n",
            "Kernel: poly, C: 3.0, Fold: 1, MSE: 321697.3212948815\n",
            "Kernel: poly, C: 3.0, Fold: 2, MSE: 310314.0689813253\n",
            "Kernel: poly, C: 3.0, Fold: 3, MSE: 423485332.97341436\n",
            "Rata - rata score: 141372448.12123019\n",
            "Kernel terbaik: linear\n",
            "Nilai C terbaik: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Definisikan grid parameter yang ingin diuji, termasuk berbagai jenis kernel\n",
        "param_grid = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': [0.1, 1.0, 3.0],\n",
        "}\n",
        "\n",
        "# Jumlah fold dalam cross-validation\n",
        "k = 3\n",
        "\n",
        "best_kernel = None\n",
        "best_C = None\n",
        "best_mean_score = float('inf')\n",
        "\n",
        "# Split data menjadi k bagian (fold)\n",
        "fold_size = len(X_train) // k\n",
        "\n",
        "for kernel in param_grid['kernel']:\n",
        "    for C in param_grid['C']:\n",
        "        scores = []\n",
        "        for i in range(k):\n",
        "\n",
        "            # Bagi data menjadi data pelatihan dan data validasi\n",
        "            start = i * fold_size\n",
        "            end = (i + 1) * fold_size\n",
        "            X_val = X_train[start:end]\n",
        "            Y_val = Y_train[start:end]\n",
        "            X_train_fold = np.concatenate((X_train[:start], X_train[end:]))\n",
        "            Y_train_fold = np.concatenate((Y_train[:start], Y_train[end:]))\n",
        "\n",
        "            if kernel == 'linear':\n",
        "                # Buat model SVR dengan kernel linear dan latih dengan data pelatihan\n",
        "                svr = linearKernel(C=C, epsilon=0.2, max_iterations=1, learning_rate=0.01)\n",
        "                svr.fit(X_train_fold, Y_train_fold)\n",
        "            elif kernel == 'rbf':\n",
        "                # Buat model SVR dengan kernel RBF dan latih dengan data pelatihan\n",
        "                svr = rbfKernel(C=C, gamma=0.1, epsilon=0.2, max_iterations=1, learning_rate=0.01)\n",
        "                svr.fit(X_train_fold, Y_train_fold)\n",
        "            elif kernel == 'poly':\n",
        "                # Buat model SVR dengan kernel polinomial dan latih dengan data pelatihan\n",
        "                svr = polyKernel(C=C, epsilon=0.2, max_iterations=1, learning_rate=0.01)\n",
        "                svr.fit(X_train_fold, Y_train_fold)\n",
        "\n",
        "            # Lakukan prediksi pada data validasi\n",
        "            Y_pred = svr.predict(X_val)\n",
        "\n",
        "            # Hitung Mean Squared Error (MSE) untuk validasi\n",
        "            mse = mean_squared_error(Y_val, Y_pred)\n",
        "            print(f\"Kernel: {kernel}, C: {C}, Fold: {i + 1}, MSE: {mse}\")\n",
        "\n",
        "            scores.append(mse)\n",
        "\n",
        "        # Hitung rata-rata skor di seluruh fold\n",
        "        mean_score = np.mean(scores)\n",
        "        print(f\"Rata - rata score: {mean_score}\")\n",
        "\n",
        "        # Periksa apakah ini adalah kombinasi kernel dan C terbaik sejauh ini\n",
        "        if mean_score < best_mean_score:\n",
        "            best_mean_score = mean_score\n",
        "            best_kernel = kernel\n",
        "            best_C = C\n",
        "\n",
        "print(\"Kernel terbaik:\", best_kernel)\n",
        "print(\"Nilai C terbaik:\", best_C)\n"
      ],
      "id": "EV2TThf1BVtR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVDZQiGpvcQD"
      },
      "source": [
        "### Evaluasi"
      ],
      "id": "fVDZQiGpvcQD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROIBioalxkXl"
      },
      "source": [
        "Pelatihan model SVR dengan kernel linear dan nilai C terbaik yang sudah didapatkan sebelumnya"
      ],
      "id": "ROIBioalxkXl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBnk_36dAKe9"
      },
      "outputs": [],
      "source": [
        "if best_kernel == 'linear':\n",
        "  best_model = linearKernel(C=best_C, epsilon=0.2, max_iterations=10, learning_rate=0.01)\n",
        "  best_model.fit(X_train, Y_train)\n",
        "elif best_kernel == 'rbf':\n",
        "  best_model = rbfKernel(C=best_C, gamma=0.1, epsilon=0.2, max_iterations=10, learning_rate=0.01)\n",
        "  best_model.fit(X_train, Y_train)\n",
        "elif best_kernel == 'poly':\n",
        "  best_model = polyKernel(C=best_C, epsilon=0.2, max_iterations=10, learning_rate=0.01)\n",
        "  best_model.fit(X_train, Y_train)"
      ],
      "id": "VBnk_36dAKe9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r2Uz_KkxtdO"
      },
      "source": [
        "Membuat prediksi pada data pengujian dengan model dengan kernel dan nilai C terbaik"
      ],
      "id": "6r2Uz_KkxtdO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ciM4FTZqigyd"
      },
      "outputs": [],
      "source": [
        "best_Y_pred = best_model.predict(X_test)"
      ],
      "id": "ciM4FTZqigyd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtlwcepexnRz"
      },
      "source": [
        "Menampilkan hasil perhitungan MSE dan R¬≤ untuk model terbaik\n",
        "\n",
        "\n"
      ],
      "id": "MtlwcepexnRz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJccRxbETcVt"
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(Y_test, best_Y_pred)\n",
        "print(\"Best Model Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "r2 = r_squared(Y_test, best_Y_pred)\n",
        "print(\"Best Model R-squared (R¬≤):\", r2)"
      ],
      "id": "TJccRxbETcVt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQlqh47oyFrs"
      },
      "source": [
        "Visualisasi hasil prediksi dari Model SVR dengan kernel linear dan C = 1.0"
      ],
      "id": "fQlqh47oyFrs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27ae8626"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Membuat plot scatter Actual vs. Predicted\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_test, Y_pred, c='b', label=\"Actual vs. Predicted\")\n",
        "plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], 'k--', lw=2, label=\"Regression Line\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"SVR: Actual vs. Predicted\")\n",
        "plt.legend()\n",
        "\n",
        "# Menghitung dan membuat plot residual\n",
        "residuals = Y_test - Y_pred\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.scatter(range(len(residuals)), residuals, c='r', label=\"Residuals\")\n",
        "plt.axhline(y=0, color='k', linestyle='--', lw=2, label=\"Residuals Mean\")\n",
        "plt.xlabel(\"Data Points\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.legend()\n",
        "\n",
        "# Menampilkan plot\n",
        "plt.show()"
      ],
      "id": "27ae8626"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5526cf7"
      },
      "source": [
        "### Hasil dan Analisis\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "id": "c5526cf7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1JJi7_M2Jee"
      },
      "source": [
        "#### Hasil\n",
        "Hasil dari program ini adalah kombinasi terbaik dari kernel dan nilai parameter C untuk model SVR yang diuji serta hasil evaluasi model dengan kombinasi parameter terbaik tersebut dengan metrik evaluasi Mean Squared Error (MSE) dan R-Squared (R¬≤). Kombinasi terbaik ini dipilih berdasarkan rata-rata hasil MSE pada setiap fold atau lipatan yang dihitung selama validasi silang (3-fold cross validation). Melalui validasi silang tersebut didapatkan kernel terbaik yang dipilih adalah \"Kernel Linear\" dengan nilai parameter C terbaik yang dipilih adalah C = 1. Kemudian berdasarkan hasil kombinasi tersebut dilakukan pelatihan model dengan menerapkan hasil dari kernel terbaik serta nilai parameter C  yang mendapatkan hasil MSE sebesar 218810.4968681095 dan hasil R¬≤ sebesar 0.4754126479174141."
      ],
      "id": "X1JJi7_M2Jee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWItRRsm2nfU"
      },
      "source": [
        "#### Analisis\n",
        "\n",
        "\n",
        "*   Kernel Linear dipilih sebagai kernel terbaik, yang merupakan salah satu kernel yang paling sederhana dalam metode Support Vector Regression (SVR).  Ini mengasumsikan bahwa hubungan antara fitur dan target adalah linier atau kerapatan data sekitar garis lurus. Ini berarti bahwa model SVR dengan kernel linear dapat memadai dalam menjelaskan pola hubungan yang bersifat linier antara fitur dan target.\n",
        "*   Nilai C yang terbaik adalah 1, dimana parameter C mengontrol trade-off antara kesalahan pelatihan dan kompleksitas model. Nilai C yang lebih tinggi mengarah pada model yang lebih kompleks dengan penalti kesalahan pelatihan yang lebih tinggi, sementara nilai C yang lebih rendah mengarah pada model yang lebih sederhana dengan penalti kesalahan pelatihan yang lebih rendah. Nilai C = 1 dipilih sebagai yang terbaik, yang mungkin adalah kompromi yang baik antara kompleksitas model dan akurasi prediksi.\n",
        "*   Hasil pelatihan model SVR dengan kernel linear dan nilai C terbaik menghasilkan MSE sebesar 218810.4968681095, dimana hasil ini masih dapat diinterpretasikan secara positif sebagai indikasi bahwa model mampu memprediksi data dengan akurasi yang cukup memadai walau masih memiliki kesalahan prediksi yang signifikan.\n",
        "*   Hasil R¬≤ sebesar 0.4754126479174141, ini menunjukkan bahwa model SVR ini mampu menjelaskan sekitar 47,5% dari variabilitas dalam data. Ini adalah indikasi bahwa model masih memberikan kontribusi yang signifikan dalam menjelaskan hubungan antara fitur dan label.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "sWItRRsm2nfU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a255fe5"
      },
      "source": [
        "#### Kesimpulan\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Berdasarkan hasil dan analisis yang telah dilakukan dalam proyek ini, kesimpulan utama adalah pemilihan kombinasi terbaik antara kernel dan nilai parameter C untuk model Support Vector Regression (SVR). Hasil tersebut menunjukkan bahwa \"Kernel Linear\" merupakan pilihan terbaik, mengindikasikan bahwa hubungan antara variabel input, seperti cuaca dan waktu, dengan permintaan sepeda cenderung linier atau terdistribusi secara linear. Nilai parameter C terbaik adalah 1, menciptakan sebuah model dengan kompleksitas yang seimbang dan penalti kesalahan pelatihan yang moderat. Dengan menggunakan kombinasi ini, kita mencapai hasil Mean Squared Error (MSE) sebesar 218810.4968681095 dan R-squared (R¬≤) sebesar 0.4754126479174141, yang menunjukkan bahwa model dengan kemampuan memadai dalam memodelkan hubungan antara variabel input dan permintaan sepeda dalam dataset."
      ],
      "id": "8a255fe5"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "qg0ptqFzWuvO"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}